# RustWebScraping
J'ai décidé de me consacrer à la réalisation d'un projet de "web scrapping" sur conseil avisé de ma conjointe -elle même apprenante en Python, 
avec l'intention d'approfondir mes connaissances en front-end (structure HTML et CSS), ainsi que  de me pousser à la pratique du langage Rust.
A l'aide de différentes sources d'informations, j'ai pu petit à petit créer mon code.

Crates utilisées : 
-tokio = { version = "1", features = ["full"] } : "tokio" permet de créer des fonctions asynchrones
-reqwest = "0.11.24" : "reqwest" permet d'envoyer des requêtes de récupération du code source d'une page web via son adresse //http
-scraper = "0.12.0" : "scraper" permet d'analyser le code source de la page web et de selectionner les données souhaitées
-csv = "1.3.0" : "csv" permet le stockage de toutes ces données dans un fichier .csv
https://www.graeco-arabic-studies.org/home.html.
Objectif du programme : 
-Scraper le code source de 





